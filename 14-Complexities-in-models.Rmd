
# Complexity in Linear Models - Spring Week Seven

```{r , echo=FALSE, eval=TRUE, include=TRUE}
klippy::klippy(c('r', 'bash'), position = c('top', 'right'), tooltip_message = 'copy to clipboard', tooltip_success = 'Copied!')
```

```{r include=FALSE}
knitr::opts_chunk$set(eval=FALSE, warning=FALSE, message=FALSE)
```

```{r, eval=T, echo=F}
library(tidyverse)
library(patchwork)

```

## Designing a Model

We are introduced to the fruitfly dataset Partridge and Farquhar (1981)^[https://nature.com/articles/294580a0]. From our understanding of sexual selection and reproductive biology in fruit flies, we know there is a well established 'cost' to reproduction in terms of reduced longevity for female fruitflies. The data from this experiment is designed to test whether increased sexual activity affects the lifespan of male fruitflies.

The flies used were an outbred stock, sexual activity was manipulated by supplying males with either new virgin females each day, previously mated females ( Inseminated, so remating rates are lower), or provide no females at all (Control). All groups were otherwise treated identically.

```{r, eval = TRUE}
fruitfly <- readRDS("data/fruitfly.RDS")

```

* **type**: type of female companion (virgin, inseminated, control(partners = 0))

* **longevity**: lifespan in days

* **thorax**: length of thorax in micrometres (a proxy for body size)

* **sleep**: percentage of the day spent sleeping

### Hypothesis

Before you start any formal analysis you should think clearly about the sensible parameters to test. In this example, we are *most* interested in the effect of sexual activity on longevity. But it is possible that other factors may also affect longevity and we should include these in our model as well, and we should think **hard** about what terms might reasonably be expected to *interact* with sexual activity to affect longevity. 

<details><summary>**Question - Which terms and interactions do you think we should include in our model?**</summary>

In this exercise I have just asked you to try and think logically about suitable predictors. For a more formal investigation you should support this with evidence where possible

* type - should definitely be included. 

* thorax - the size of the flies could determine longevity. Carreira et al (2009)^[https://www.nature.com/articles/hdy2008117]

* sleep - sleep could easily help determine longevity. Thompson et al (2020)^[https://journals.biologists.com/bio/article/9/9/bio054361/225803/Sleep-length-differences-are-associated-with]

* type:sleep - the amount that sleep (rest) helps promote longevity could change depending on how much activity the fly engages in when awake. Chen et al (2017)^[https://www.nature.com/articles/s41467-017-00087-5#:~:text=In%20this%20study%2C%20we%20show,but%20aroused%20females%20sleep%20more]

Other interactions *could* be included but you should have a strong reason for them. 

</details>

## Checking the data

You should now import, clean and tidy your data. Making sure it is in tidy format, all variables have useful names, and there are no mistakes, missing data or typos.

Based on the variables you have decided to test you should start with some simple visualisations, to understand the distribution of your data, and investigate visually the relationships you wish to test.

This is full two-by-two plot of the entire dataset, but you should try and follow this up with some specific plots. 

```{r, eval = TRUE, warning = FALSE, message = FALSE}

GGally::ggpairs(fruitfly)

```

<details><summary>**EXERCISE - Think carefully about the plots you should make to investigate the potential differences and relationships you wish to investigate - examples hidden behing this dropdown**</summary>


In this first figure - we can investigate whether there is an obvious difference in the longevities of males across the three treatments

```{r, message = FALSE, eval = TRUE, fig.cap = "A density distribution of longevity across the three sexual activity treatments"}

library(ggridges)

colours <- c("cyan", "darkorange", "purple")

fruitfly %>% 
  ggplot(aes(x = longevity, y = type, fill = type))+
  geom_density_ridges(alpha = 0.5)+
  scale_fill_manual(values = colours)+
  theme_minimal()+
  theme(legend.position = "none")


```
With careful thought we can construct figures that help us investigate the distribution of multiple potential predictors at once. Here we can overlay body size onto the three treatments. Here it does look as though larger flies have a longer lifespan than smaller flies. Is this trend enough of a deviation to reject a null hypothesis of no effect?

```{r, message = FALSE, eval = TRUE, fig.cap = "A boxplot of longevity across three treatments of sexual activity. Individual points represent individual males, where the size of each point represents thorax length."}

fruitfly %>% 
  ggplot(aes(x=type, y = longevity, fill = type))+
  geom_boxplot(alpha = 0.4)+
  geom_jitter(aes(size = thorax),
              alpha = 0.6,
              width = 0.4,
              shape = 21)+
  scale_fill_manual(values = colours)+
    guides(fill = "none",
         colour = "none")+
  theme_minimal()



```
We are also interested in the potential effect of sleep on activity, we can construct a scatter plot of sleep against longevity, while including body size as a covariate. In these faceted plots - do the data points appear to follow the trendline? Are the trendlines moving in the same direction? Investigating these can help us determine is there much evidence of a potential effect of sleep, is there evidence for whether this might be an additive effect or one which interacts with the the three treatments?

```{r, message = FALSE, eval = TRUE, fig.cap = "A scatter plot of proportion of time spent sleeping against longevity with a linear model trendline. Points represent individual flies, and the size of each point represents thorax length (mm)."}

fruitfly %>% 
ggplot(aes(x=sleep, y = longevity, fill = type))+
  geom_point(aes(size = thorax,
                 fill = type),
             shape = 21,
             alpha = 0.4)+
  geom_smooth(method = "lm", colour = "black",
              se = FALSE)+
  scale_fill_manual(values = colours)+
  guides(fill = "none",
         colour = "none")+
  facet_wrap(~ type)+
  theme_minimal()

```
</details>

## Designing a model

```{block, type = "rmdnote"}
When you include an interaction term, the numbers produced from this are how much **more** or **less** the mean estimate is than if you just combined the main effects. 
```

```{r, eval = TRUE, echo =F}
# a full model
flyls1 <- lm(longevity ~ type + thorax + sleep + type:sleep, data = fruitfly)

```

```{r}
# a full model
flyls1 <- lm(longevity ~ type + thorax + sleep + type:sleep, data = fruitfly)

```

```
# A tibble: 7 x 7
  term                  estimate std.error statistic  p.value conf.low conf.high
  <chr>                    <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>
1 (Intercept)           -57.5       11.4      -5.07  1.52e- 6  -80.0    -35.0   
2 typeInseminated         7.99       5.34      1.50  1.37e- 1   -2.59    18.6   
3 typeVirgin            -10.9        5.47     -1.99  4.86e- 2  -21.7     -0.0664
4 thorax                143.        13.4      10.6   6.53e-19  116.     169.    
5 sleep                   0.0904     0.189     0.480 6.32e- 1   -0.283    0.464 
6 typeInseminated:sleep  -0.197      0.208    -0.944 3.47e- 1   -0.609    0.216 
7 typeVirgin:sleep       -0.112      0.217    -0.519 6.05e- 1   -0.541    0.317 
```
> Note because we have included an interaction effect the number of terms is quite long and takes more consideration to understand. We can see for the individual estimates that it does not appear that the interaction is having a strong effect (estimate) and this does not appear to be different from a null hypothesis of no interaction effect. But we we should use an *F* test to look at the overall effect to be sure. 


<details><summary>**Question - From the model summary table could you say what the mean longevity of a male with a 0.79mm thorax, that sleeps for 22% of the day and is paired with virgin females would be?**</summary>

```{r}
# intercept
coef(flyls1)[1] + 
  
# 1*coefficient for virgin treatment  
coef(flyls1)[3] + 
  
# 0.79 * coefficient for thorax size  
(coef(flyls1)[4]*0.79) + 
  
# 22 * coefficient for sleep  
(coef(flyls1)[5]*22) + 

# 22 * 1 * coefficient for interaction
(coef(flyls1)[7]*22*1)
```
```
   43.66344 days

```

</details>

## Model checking & collinearity

Before we start playing with the terms in our model, we should check to see if this is even a good way of fitting and measuring our data. We should check the assumptions of our model are being met.

```{r, eval = TRUE, message = FALSE, warning = FALSE, fig.height=9}

performance::check_model(flyls1)

```

<details><summary>**Question - IS the assumption of homogeneity of variance met?**</summary>

* Mostly - the reference line is fairly flat (there is a slight curve).

* It looks as though there might be some increasing heterogeneity with larger values, though very minor.

VERDICT, pretty much ok, should be fine for making inferences. 

With a slight curvature this could indicate that you *might* get a better fit with a transformation, or perhaps that there is a missing variable that if included in the model would improve the residuals. In this instance I wouldn't be overly concerned. See here for a great explainer on intepreting residuals^[https://www.qualtrics.com/support/stats-iq/analyses/regression-guides/interpreting-residual-plots-improve-regression/].

</details>

<details><summary>**Question - ARE the residuals normally distributed?**</summary>

Yes - the QQplot looks pretty good, a very minor indication of a right skew, but nothing to worry about. 

[Interpreting QQ plots][What is a Quantile-Quantile (QQ) plot?]

</details>


<details><summary>**Question - IS their an issue with Collinearity?**</summary>

This graph clearly shows there **is** collinearity. But this is not unusual when we include an *interaction term*, if we see evidence of collinearity in terms that are not part of an interaction **then** we should take another look^[https://easystats.github.io/performance/reference/check_collinearity.html].

What can you do about collinearity in main effects? 1) Nothing 2) Transform 3) Drop one of the terms. 

The `check_performance()` function produces a visual summary of a Variance Inflation Factor produced from the `vif()` function. This is a measure of the standard error of each estimated coefficient. If this is very larger (greater than 5 or 10), this indicates the model has problems estimating the coefficient. This does not affect model predictions, but makes it more difficult to determine the estimate change from a predictor. 

```{r}
car::vif(flyls1)

```

```
             GVIF Df GVIF^(1/(2*Df))
type       12.479  2           1.880
thorax      1.053  1           1.026
sleep       8.751  1           2.958
type:sleep 38.749  2           2.495

```

</details>

### Data transformations

The most common issues when trying to fit simple linear regression models is that our response variable is not normal which violates our modelling assumption. There are two things we can do in this case:

* Variable transformation e.g `lm(sqrt(x) ~ y, data = data)`
    
    - Can sometimes fix linearity
    
    - Can sometimes fix non-normality and heteroscedasticity (i.e non-constant variance) 
    
* Generalized Linear Models (GLMs) to change the error structure (i.e the assumption that residuals need to be normal - see next week.)

### BoxCox

```{block, type="rmdnote"}
The BoxCox gets its name from its two inventors, George Box and David Cox. 
Implemented by the MASS package, when applied to a linear model it sytematically applies transformations by raising the y variable to a power (lambda).

The R output for the boxcox() function plots a maximum likelihood curve (with a 95% confidence interval - drops down as dotted lines) for the best transformation for fitting the data to the model.

```

```{r, eval = TRUE, echo = FALSE, warning = FALSE, message = FALSE}
library(kableExtra)

`lambda value` <- c(0, 0.5, 1, 2 )

`transformation` <- c("log(Y)", "sqrt(Y)", "Y", "Y^1")

box <- tibble(`lambda value`, `transformation`)

box %>% 
   kbl(caption = "Common Box-Cox Transformations", 
    booktabs = T) %>% 
   kable_styling(full_width = FALSE, font_size=16)

```

```{r, fig.cap = "standard curve fitted by maximum likelihood, dashed lines represent the 95% confidence interval range for picking the 'best' transformation for the dependent variable"}
# run this, pick a transformation and retest the model fit
MASS::boxcox(flyls1)

```

<details><summary>**Question - Does the fit of the model improve with a square root transformation?**</summary>

Not really, despite the suggestion that a sqrt transformation would improve the model, residual fits are not really any better - so we might as well stick with the original scale.

</details>



## Model selection

```{r}
# use drop1 function to remove top-level terms
drop1(flyls1, test = "F")

```
```
Single term deletions

Model:
longevity ~ type + thorax + sleep + type:sleep
           Df Sum of Sq   RSS    AIC  F value Pr(>F)    
<none>                  14994 612.39                    
thorax      1   14347.5 29342 694.31 112.9088 <2e-16 ***
type:sleep  2     130.1 15125 609.47   0.5121 0.6006    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

```

Based on this ANOVA table, we do not appear to have a strong rationale for keeping the interaction term in the model (AIC or F-test). Therefore we can confidently remove the interaction, simplifying our model and making interpretation easier. 

```{r, eval = TRUE, echo = F}
flyls2 <- lm(longevity ~ type + thorax + sleep, data = fruitfly)

```


```{r}

flyls2 <- lm(longevity ~ type + thorax + sleep, data = fruitfly)

drop1(flyls2, test = "F")

```
```
Single term deletions

Model:
longevity ~ type + thorax + sleep
       Df Sum of Sq   RSS    AIC  F value    Pr(>F)    
<none>              15125 609.47                       
type    2    7576.9 22701 656.23  30.0578 2.617e-11 ***
thorax  1   15282.8 30407 694.77 121.2556 < 2.2e-16 ***
sleep   1      86.3 15211 608.18   0.6846    0.4097    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
```

<details><summary>**Question - Should we drop sleep from this model?**</summary>

There is good reason to remove non-significant *interaction terms* from a model, they complicate estimates and make interpretations more difficult. For **main** effects things are a little more ambiguous. 

When the main aim is prediction, it makes sense to be cautious and retain non-significant terms, as extra terms make no difference to the R^2 of a model. 

When the focus is on hypothesis testing, then removal of non-significant terms can help produce a 'true' model, but this is optional. Generally speaking it is often simpler to leave main effects in the model (you should have carefully considered the terms which were included in the first place). 

In this example we can also see that AIC has not really changed - so the quality of the model is also not improved vby dropping this term. 

</details>


## Posthoc

Using the [emmeans](https://aosmith.rbind.io/2019/03/25/getting-started-with-emmeans/) package is a very easy way to produce the estimate mean values (rather than mean differences) for different categories `emmeans`. If the term `pairwise` is included then it will also include post-hoc pairwise comparisons between all levels with a tukey test `contrasts`.

```{r}

emmeans::emmeans(flyls2, specs = pairwise ~ type + thorax + sleep)

```
```
$emmeans
 type        thorax sleep emmean   SE  df lower.CL upper.CL
 Control      0.821  23.5   61.3 2.26 120     56.8     65.8
 Inseminated  0.821  23.5   64.9 1.59 120     61.8     68.1
 Virgin       0.821  23.5   48.0 1.59 120     44.9     51.2

Confidence level used: 0.95 

$contrasts
 contrast                                            estimate   SE  df t.ratio p.value
 Control 0.82096 23.464 - Inseminated 0.82096 23.464    -3.63 2.77 120 -1.309  0.3929 
 Control 0.82096 23.464 - Virgin 0.82096 23.464         13.25 2.76 120  4.796  <.0001 
 Inseminated 0.82096 23.464 - Virgin 0.82096 23.464     16.87 2.25 120  7.508  <.0001 

P value adjustment: tukey method for comparing a family of 3 estimates 

```
> Note - for continuous variables (sleep and thorax) - emmeans has set these to the mean value within the dataset, so comparisons are constant between categories at the average value of all continuous variables. 

## Write-up

<details><summary>**Write-up- Can you write a Results section?**</summary>

I tested the hypothesis that sexual activity is costly for male *Drosophila melanogaster* fruitflies. Previous research indicated that sleep deprived males are less attractive to females, this would indicate that levels of sexual activity might be affected by sleep and impact the effect on longevity, as such this was included as an interaction term in the full model. Body size is also know to affect lifespan, as such this was included as a covariate in the mode. 

There was a small interaction effect of decreased lifespan with increasing sleep in the treatment groups compared to control in our samples, but this was not significantly different from no effect (F~2,118~ = 0.512, P = 0.6), and was therefore dropped from the full model (Table 15.1). 

```{r, echo = F, eval = TRUE, warning = F, message = F}
library(kableExtra)
flyls2 %>% broom::tidy(conf.int = T) %>% 
 select(-`std.error`) %>% 
mutate_if(is.numeric, round, 2) %>% 
kbl(col.names = c("Predictors",
                    "Estimates",
                    "Z-value",
                    "P",
                    "Lower 95% CI",
                    "Upper 95% CI"),
      caption = "Linear model coefficients", 
    booktabs = T) %>% 
   kable_styling(full_width = FALSE, font_size=16)
```

There was a significant overall effect of treatment on male longevity (Linear model: F~2,120~ = 30.1, P < 0.001), with males paired to virgin females having the lowest mean longevity (48 days, [95%CI: 44.9 - 51.2]) (when holding body size and sleep constant), compared to control males (61.3 days [56.8 - 65.8]) and males paired with inseminated females (64.9 days [61.8 - 68.1 days]). 

Post hoc analysis showed that these differences were statistically significant for males paired with control females compared to the inseminated (Tukey test: t~120~ = 4.8, P < 0.001)  and virgin groups (t~120~ = 7.5, P < 0.001), but there was no overall evidence of a difference between inseminated and virgin groups (t~120~ = -1.309  P < 0.3929) (Figure 19.4). 

Comparing the treatment effects against other predictors of longevity such as body size and sleep, I found that sleep had a very small effect on longevity (mean change -0.05 days [-0.18 - 0.07]) which was not significantly different from no effect (Linear model: F~1,120~ = 0.68, P = 0.41). Body size (taken from thorax length) was a significant predictor of longevity (F~1,120~ = 121, P < 0.001), with each 0.1 mm increase in body size adding 14.4 days to the individual lifespan [11.8 - 17]. It appears as though body size has a stronger effect on longevity than treatment, indicating that while there is a measurable cost of sexual activity to males, it may be less severe than in females (not compared here), and less severe than other measurable predictors. 

> Note - there are formal measures of partial effect sizes for complex linear models, but they are not often reported in papers, and become increasingly complicated to produce and ensure they are robust, so I have not tried to compute these here.^[https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00863/full]

> Note - for the effect of thorax, I could also have reported t from the summary - as it is a single `level`, continuous effect so here F = t^2. 

```{r, echo = F, eval = TRUE}

# optional extras for adding animal silhouette
library(rphylopic)
# search for the right image in the database
fruitfly_phylo <- name_search(text = "Drosophila melanogaster", options = "namebankID")[[1]] 

# name_images(uuid = fruitfly$uid[1])

# extract the ID of thr right image
fruitfly_2 <- name_images(uuid = fruitfly_phylo$uid[1])$same[[2]]$ui

# get the actual image
fruitfly_pic <- image_data(fruitfly_2, size = 256)[[1]]
```

```{r, eval = F, echo = F}
equation1=function(x){coef(flyls2)[4]*x+coef(flyls2)[5]*23.5+coef(flyls2)[1]}
equation2=function(x){coef(flyls2)[4]*x+coef(flyls2)[5]*23.5+coef(flyls2)[1]+coef(flyls2)[2]}
equation3=function(x){coef(flyls2)[4]*x+coef(flyls2)[5]*23.5+coef(flyls2)[1]+coef(flyls2)[3]}


flyls2 %>% 
  ggplot(aes(x=thorax, y = longevity, colour = type))+
  stat_function(fun=equation1,geom="line",color="cyan")+
  stat_function(fun=equation2,geom="line",color="darkorange")+
  stat_function(fun=equation3,geom="line",color="purple")+
  geom_point()+
  scale_colour_manual(values = colours)+
  theme_minimal()+
  theme(legend.position = "none")+ 
  add_phylopic(fruitfly_pic2, alpha = 0.8, x = 0.7, y = 80, ysize = 10)

```

```{r, echo = F, eval = TRUE, message = F, warning = F, fig.cap = " A scatter plot of longevity against body size across three treatments of differening male sexual activity. Fitted model slopes are from the reduced linear model (main effects only of thorax size, sleep and treatment group), with 95% confidence intervals, circles are individual data points. Marginal plots are density plot distributions for thorax length and longevity split by treatments."}

# density plot of thorax length by treatment
marginal1 <- fruitfly %>% 
  ggplot()+
  geom_density(aes(x = thorax, fill = type),
               alpha = 0.5)+
  scale_fill_manual(values = colours)+
  theme_void()+
  theme(legend.position = "none")

# density plot of longevity by treatment
marginal2 <- fruitfly %>% 
  ggplot()+
  geom_density(aes(x = longevity, fill = type),
               alpha = 0.5)+
  scale_fill_manual(values = colours)+
  theme_void()+
  coord_flip()


# create a new dataset where all sleep values are set to a constant (mean) values - see the emmeans table

fruitfly_2 <- fruitfly %>% 
  mutate(sleep = mean(sleep))

# use the final model to produce model predictions set to the new constant sleep dataframe
model_plot <- broom::augment(flyls2, newdata = fruitfly_2, interval = "confidence") %>% 
  ggplot(aes(x=thorax, y = .fitted, colour = type, fill = type))+
  geom_ribbon(aes(ymin=.lower, ymax=.upper), alpha = 0.2)+
    geom_line(linetype = "dashed", show.legend = FALSE)+
  geom_point(data = fruitfly, aes(x = thorax, y = longevity),
             show.legend = FALSE)+
  scale_colour_manual(values = colours)+
  scale_fill_manual(values = colours)+
  labs(y = "Lifespan in days",
       x = "Thorax length (mm)",
       fill = "Type of female exposure")+
  guides(colour = "none")+
  theme_classic()+
  theme(legend.position = "none")+
  add_phylopic(fruitfly_pic, alpha = 0.8, x = 0.7, y = 80, ysize = 10)



layout <- "
AAA#
BBBC
BBBC
BBBC"


marginal1+model_plot+marginal2 +plot_layout(design = layout)

```

</details>


## Summary

In this chapter we have worked with our scientific knowledge to develop testable hypotheses and built statistical models to formally assess them. We now have a working pipeline for tackling complex datasets, developing insights and producing and explaining robust linear models. 

### Checklist

* Think carefully about the hypotheses to test, use your scientific knowledge and background reading to support this

* Import, clean and understand your dataset: use data visuals to investigate trends and determine if there is clear support for your hypotheses

* Fit a linear model, including interaction terms with caution

* Investigate the fit of your model, understand that parameters may never be perfect, but that classic patterns in residuals may indicate a poorly fitting model - sometimes this can be fixed with careful consideration of missing variables or through data transformation

* Test the removal of any interaction terms from a model, look at AIC and significance tests

* Make sure you understand the output of a model summary, sense check this against the graphs you have made

* The direction and size of any effects are the priority - produce estimates and uncertainties. Make sure the observations are clear.

* Write-up your significance test results, taking care to report not just significance (and all required parts of a significance test). Do you know *what* to report? Within a complex model - reporting *t* will indicate the slope of the line for that single term against the intercept, *F* is the overall effect of a predictor across all levels, *post-hoc* if you wish to compare across all levels. 

* Well described tables and figures can enhance your results sections - take the time to make sure these are informative and attractive. 


## Supplementary code

 Code to pipe the tidy model summary to kable to produce a table

```{r, eval = F, warning = F, message = F}
library(kableExtra)
flyls2 %>% broom::tidy(conf.int = T) %>% 
 select(-`std.error`) %>% 
mutate_if(is.numeric, round, 2) %>% 
kbl(col.names = c("Predictors",
                    "Estimates",
                    "Z-value",
                    "P",
                    "Lower 95% CI",
                    "Upper 95% CI"),
      caption = "Linear model coefficients", 
    booktabs = TRUE) %>% 
   kable_styling(full_width = FALSE, font_size=16)
```

`sjPlot` A really nice package that helps produce model summaries for you automatically

```{r}
library(sjPlot)
tab_model(flyls2)
```

Produce phylopic images^[https://jacintak.github.io/post/2021-08-01-rphylopic/]

```{r}

# optional extras for adding animal silhouette
library(rphylopic)
# search for the right image in the database
fruitfly_phylo <- name_search(text = "Drosophila melanogaster", options = "namebankID")[[1]] 

# name_images(uuid = fruitfly$uid[1])

# extract the ID of thr right image
fruitfly_2 <- name_images(uuid = fruitfly_phylo$uid[1])$same[[2]]$ui

# get the actual image
fruitfly_pic <- image_data(fruitfly_2, size = 256)[[1]]
```


Manual calculation of regression lines

```{r, eval = F}
equation1=function(x){coef(flyls2)[4]*x+coef(flyls2)[5]*23.5+coef(flyls2)[1]}
equation2=function(x){coef(flyls2)[4]*x+coef(flyls2)[5]*23.5+coef(flyls2)[1]+coef(flyls2)[2]}
equation3=function(x){coef(flyls2)[4]*x+coef(flyls2)[5]*23.5+coef(flyls2)[1]+coef(flyls2)[3]}


flyls2 %>% 
  ggplot(aes(x=thorax, y = longevity, colour = type))+
  stat_function(fun=equation1,geom="line",color="cyan")+
  stat_function(fun=equation2,geom="line",color="darkorange")+
  stat_function(fun=equation3,geom="line",color="purple")+
  geom_point()+
  scale_colour_manual(values = colours)+
  theme_minimal()+
  theme(legend.position = "none")+ 
  add_phylopic(fruitfly_pic2, alpha = 0.8, x = 0.7, y = 80, ysize = 10)

```

Code to produce a model summary plot that plots the exact slopes calculate by your model from using `augment()`

```{r}

# density plot of thorax length by treatment
marginal1 <- fruitfly %>% 
  ggplot()+
  geom_density(aes(x = thorax, fill = type),
               alpha = 0.5)+
  scale_fill_manual(values = colours)+
  theme_void()+
  theme(legend.position = "none")

# density plot of longevity by treatment
marginal2 <- fruitfly %>% 
  ggplot()+
  geom_density(aes(x = longevity, fill = type),
               alpha = 0.5)+
  scale_fill_manual(values = colours)+
  theme_void()+
  coord_flip()


# create a new dataset where all sleep values are set to a constant (mean) values - see the emmeans table

fruitfly_2 <- fruitfly %>% 
  mutate(sleep = mean(sleep))

# use the final model to produce model predictions set to the new constant sleep dataframe
model_plot <- broom::augment(flyls2, newdata = fruitfly_2, interval = "confidence") %>% 
  ggplot(aes(x=thorax, y = .fitted, colour = type, fill = type))+
  geom_ribbon(aes(ymin=.lower, ymax=.upper), alpha = 0.2)+
    geom_line(linetype = "dashed", show.legend = FALSE)+
  geom_point(data = fruitfly, aes(x = thorax, y = longevity),
             show.legend = FALSE)+
  scale_colour_manual(values = colours)+
  scale_fill_manual(values = colours)+
  labs(y = "Lifespan in days",
       x = "Thorax",
       fill = "Female exposure")+
  guides(colour = "none")+
  theme_classic()+
  theme(legend.position = "none")+
  add_phylopic(fruitfly_pic, alpha = 0.8, x = 0.7, y = 80, ysize = 10)



layout <- "
AAA#
BBBC
BBBC
BBBC"


marginal1+model_plot+marginal2 +plot_layout(design = layout)

```

# Generalized Linear Models

```{r, echo = F}
eta_squared(aov(flyls1, test= "Chisq")) # partial eta for glms

```

## Motivation

In the previous workshop we have seen that linear models are a powerful modelling tool. 
However, we have to satisfy the following assumptions:

1. A **linear** relationship between predictors and the mean response value.
2. Variances are equal across all predicted values of the response (**homoscedatic**)
3. Errors are **normally** distributed. 
4. Samples collected at **random**.
5. No omitted variables of importance

If assumptions 1-3 are violated we can often *transform* our response variable
to try and fix this (Box-Cox & transformation).
However, in a lot of other cases this is either not possible (e.g binary output) 
or we want to explicitly model the underlying distribution (e.g count data). 
Instead, we can use *Generalised* Linear Models (GLMs) that let us change the *error structure* (assumption 3) to something other than a normal distribution.

## Generalised Linear Models (GLMs)

**Generalised Linear Models** (GLMs) have:

1. A linear predictor.
2. An **error/variance structure**.
3. A **link function** (like an 'internal' transformation).

The first (1) should be familiar, its everything that comes after the `~` in a linear model formula. Or as an equation $\beta_0 + \beta_1$. The second (2) should also be familiar, variance measures the error structure of the model $\epsilon$. An ordinary least squares model uses the normal distribution, but *GLMs* are able to use a wider range of distributions including poisson, binomial and Gamma. The third component (3) is less familiar, the link function is the equivalent of a transformation in an ordinary least squares model. However, rather than transforming *the data*, we transform the predictions made by the linear predictors. Common link functions are log and square root. 

```{block, type = "rmdnote"}
**Maximum Likelihood** - Generalised Linear Models fit a regression line by finding the parameter values that best fit the model to the data. This is very similar to the way that ordinary least squares finds the line of best fit by reducing the sum of squared errors. In fact for data with normally distributed residuals, the particular form of maximum likelihood **is** least squares. 

However the normal (gaussian) distribution will not be a good model for lots of other types of data, binary data, is a good example and one we will investigate in this workshop. 

Maximum likelihood provides a more generalized approach to model fitting that includes, but is broader than, least squares. 

An advantage of the least squares method we have been using is that we can generate precise equations for the fit of the line. In contrast the calculations for GLMs (which are beyond the scope of this course) are approximate, essentially multiple potential best fit lines are made and compared against each other. 

You will see two main differences in a GLM output:

If the model is one where the mean and variance are calculated *separately* (e.g. for most normal distributions), unceratinty estimates use the *t* distribution; and when we compare complex to simplified models (using `anova()` or `drop1()`) we use the *F*-test. 

However, when we provide distributions where the mean and variance are expected to change *together* (Poisson and Binomial), then we calculate uncertainty estimates using the *z* distribution, and compare models with the *chi-square* distribution.

```


The simple linear regression model we have used so far is a special cases of a GLM:

```{r eval=F}
lm(height ~ weight)
```

is equivalent to

```{r eval = F}
glm(height ~ weight, family=gaussian(link=identity))
```

Compared to [`lm()`](https://www.rdocumentation.org/packages/stats/versions/3.5.1/topics/lm), the [`glm()`](https://www.rdocumentation.org/packages/stats/versions/3.5.1/topics/glm) function takes an additional argument called [`family`](https://www.rdocumentation.org/packages/stats/versions/3.5.1/topics/family), which
specifies the error structure **and** link function.

The default **link function** for the normal (Gaussian) distribution is the **identity**, *where no transformation is needed*i.e. for mean $\mu$ we have:  

$$
\mu = \beta_0 + \beta_1 X
$$

Defaults are usually good choices (shown in bold below):

| Family | Link |
|:------:|:----:|
`gaussian` | **`identity`** |
`binomial` | **`logit`**, `probit` or `cloglog` |
`poisson` | **`log`**, `identity` or `sqrt` |
`Gamma` | **`inverse`**, `identity` or `log` |
`inverse.gaussian` | **`1/mu^2`** |
`quasibinomial`	| **`logit`**
`quasipoisson` | **`log`**

<details><summary>**EXERCISE - Using the fruitfly data introduced last week fit a linear model with lifespan as a response variable and sleep, type and thorax as explanatory variables. Compare this to a glm fitted with a gaussian error distribution and identity link for the mean**</summary>

```{r}
flyls <- lm(longevity ~ type + thorax + sleep, data = fruitfly)
summary(flyls)
```

```
Call:
lm(formula = longevity ~ type + thorax + sleep, data = fruitfly)

Residuals:
    Min      1Q  Median      3Q     Max 
-28.153  -6.836  -2.191   7.196  29.046 

Coefficients:
                 Estimate Std. Error t value Pr(>|t|)    
(Intercept)     -56.04502   11.17882  -5.013 1.87e-06 ***
typeInseminated   3.62796    2.77122   1.309    0.193    
typeVirgin      -13.24603    2.76198  -4.796 4.70e-06 ***
thorax          144.43008   13.11616  11.012  < 2e-16 ***
sleep            -0.05281    0.06383  -0.827    0.410    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 11.23 on 120 degrees of freedom
Multiple R-squared:  0.6046,	Adjusted R-squared:  0.5914 
F-statistic: 45.88 on 4 and 120 DF,  p-value: < 2.2e-16
```

```{r}
flyglm <- glm(longevity ~ type + thorax + sleep, 
             family = gaussian(link = "identity"),
             data = fruitfly)
summary(flyglm)
```
```
glm(formula = longevity ~ type + thorax + sleep, family = gaussian(link = "identity"), 
    data = fruitfly)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-28.153   -6.836   -2.191    7.196   29.046  

Coefficients:
                 Estimate Std. Error t value Pr(>|t|)    
(Intercept)     -56.04502   11.17882  -5.013 1.87e-06 ***
typeInseminated   3.62796    2.77122   1.309    0.193    
typeVirgin      -13.24603    2.76198  -4.796 4.70e-06 ***
thorax          144.43008   13.11616  11.012  < 2e-16 ***
sleep            -0.05281    0.06383  -0.827    0.410    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for gaussian family taken to be 126.0381)

    Null deviance: 38253  on 124  degrees of freedom
Residual deviance: 15125  on 120  degrees of freedom
AIC: 966.2

Number of Fisher Scoring iterations: 2
```
They are exactly the same. This is not surprising, as the maximum likelihood being fitted here is the same as an ordinary least squares model.

</details>


### Workflow for fitting a GLM

* Exploratory data analysis
* Choose suitable error term
* Choose suitable mean function (and link function)
* Fit model
    * Residual checks and model fit diagnostics
    * Revise model (transformations etc.)
* Model simplification if required
* Check final model again

```{block, type = "rmdnote"}
When you transform your data e.g. with a log or sqrt, this changes the mean and variance at the same time (everything gets squished down). This might be fine, but can lead to difficult model fits if you need to reduce unequal variance but this leads to a change (often curvature) in the way the predictors fit to the response variable. 

GLMs model the mean and variability independently. So a link function produces a transformation between predictors and the mean, and the relationship between the mean and data points is modelled separately. 

```

## Poisson regression (for count data or rate data)

Count or rate data are ubiquitous in the life sciences (e.g number of parasites per microlitre of blood, number of species counted in a particular area). These type of data are **discrete** and **non-negative**.
In such cases assuming our response variable to be normally distributed is not typically sensible. 
The Poisson distribution lets us model count data explicitly.

Recall the simple linear regression case (i.e a GLM with a Gaussian error structure and identity link). For the sake of clarity let's consider a single explanatory variable where $\mu$ is the mean for *Y*:

$$
\begin{aligned}
\mu & = \beta_0 + \beta_1X
\end{aligned}
$$

The mean function is **unconstrained**, i.e the value of $\beta_0 + \beta_1X$ can range from $-\infty$ to $+\infty$. If we want to model count data we therefore want to **constrain** this mean to be positive only. Mathematically we can do this by taking the **logarithm** of the mean (the log is the default link for the Poisson distribution). We then assume our count data variance to be Poisson distributed (a discrete, non-negative distribution), to obtain our Poisson regression model (to be consistent with the statistics literature we will rename $\mu$ to $\lambda$):

$$
\begin{aligned}
Y & \sim \mathcal{Pois}(\lambda) \\
\log{\lambda} & = \beta_0 + \beta_1X
\end{aligned}
$$

> Note - the relationship between the mean and the data is modelled by Poisson variance. The relationship between the predictors and the mean is modelled by a log transformation. 

The **Poisson** distribution has the following characteristics:

* **Discrete** variable, defined on the range $0, 1, \dots, \infty$.
* A single ***rate*** parameter $\lambda$, where $\lambda > 0$.
* **Mean** = $\lambda$  
* **Variance** = $\lambda$

So we model the variance as equal to the mean - as the mean increases so does the mean. 

```{r, eval = T, echo=F}
#cols <- c("#F4ABAB", "#91CDF2", "#5AA566", "#A57C42")
cols <- c("#377eb8", "#4daf4a", "#984ea3") # colorbrewer
par(mfrow = c(3, 1))
x <- 0:20
rates <- c(1, 5, 10)
barplot(dpois(x, rates[1]), col = cols[1], ylab = "Probability", xlab = "X", main = paste0("lambda = ", rates[1]), names.arg = x)
for(i in 2:length(rates)) barplot(dpois(x, rates[i]), col = cols[i], ylab = "Probability", xlab = "X", main = paste0("lambda = ", rates[i]), names.arg = x)
par(mfrow = c(1, 1))
```


```{r, eval=TRUE, echo=FALSE, out.width="80%", fig.alt= "Poisson distribution on an exponential line"}
knitr::include_graphics("images/poisson.png")
```


So for the Poisson regression case we assume that the mean and variance are the same.
Hence, as the mean *increases*, the variance *increases* also (**heteroscedascity**).
This may or may not be a sensible assumption so watch out! Just because a Poisson distribution *usually* fits well for count data, doesn't mean that a Gaussian distribution *can't* always work.

Recall the link function between the predictors and the mean and the rules of logarithms (if $\log{\lambda} = k$, then $\lambda = e^k$):

$$
\begin{aligned}
\log{\lambda} & = \beta_0 + \beta_1X \\
\lambda & = e^{\beta_0 + \beta_1X }
\end{aligned}
$$
Thus we are effectively modelling the observed counts (on the original scale) using an exponential mean function.

```{r, echo = F, eval = F, fig.width = 10, fig.height = 5}
set.seed(10)
x <- rnorm(100, 0, 1)
x <- x - min(x)
lambda <- x
y <- rpois(100, lambda = exp(lambda))
y.glm <- glm(y ~ x, family = poisson)
par(mfrow = c(1, 2))
plot(x, y)
lines(seq(min(x), max(x), length = 100), exp(coef(y.glm)[1] + coef(y.glm)[2] * seq(min(x), max(x), length = 100)), 
      col='black', lwd=2)
plot(fitted(y.glm), y - fitted(y.glm), xlab = "Fitted values", ylab = "Residuals", main = "")
abline(h = 0, lty = 2)
par(mfrow = c(1, 1))
```

## Example: Cuckoos

```{r, echo=FALSE, fig.width = 10, fig.height = 5}
knitr::include_graphics("images/cuckoo.jpg")
```

In a study by [Kilner *et al.* (1999)](http://www.nature.com/nature/journal/v397/n6721/abs/397667a0.html), the authors
studied the begging rate of nestlings in relation to total mass of the brood of **reed warbler chicks** and **cuckoo chicks**.
The question of interest is:

> How does nestling mass affect begging rates between the different species?


```{r, eval=FALSE}
cuckoo <- read_csv("data/cuckoo.csv")
```

```{r, echo=FALSE, eval=TRUE, message = FALSE, warning = FALSE}
cuckoo <- read_csv("data/cuckoo.csv")
```

```{r}
head(cuckoo)
```

The data columns are:

* **Mass**: nestling mass of chick in grams
* **Beg**: begging calls per 6 secs
* **Species**: Warbler or Cuckoo

```{r, eval = T, echo = F, fig.height=6, fig.width=7}
ggplot(cuckoo, aes(x=Mass, y=Beg, colour=Species)) + geom_point()
```

There seem to be a relationship between mass and begging calls and it could
be different between species. It is tempting to fit a linear model to this data. 
In fact, this is what the authors
of the original paper did; **reed warbler chicks** (solid circles, dashed fitted line) and 
**cuckoo chick** (open circles, solid fitted line):

```{r, echo=FALSE, eval = T, fig.width = 10, fig.height = 5}
knitr::include_graphics("images/original.png")
```

This model is inadequate. It is predicting **negative** begging calls *within* the 
range of the observed data, which clearly does not make any sense.

Let us display the model diagnostics plots for this linear model.

```{r, eval = T}
## Fit model
## There is an interaction term here, it is reasonable to think that how calling rates change with size might be different between the two species.
cuckoo_ls1 <- lm(Beg ~ Mass+Species+Mass:Species, data=cuckoo) 
```

```{r, eval = T}
performance::check_model(cuckoo_ls1)
```


The residuals plot depicts a strong "funnelling" effect, highlighting that the model assumptions are violated.
We should therefore try a different model structure.

The response variable in this case is a classic **count data**: **discrete** and bounded below by zero (i.e we cannot have negative counts). We will therefore try a **Poisson model** using the canonical **log** link function for the mean:

$$
    \log{\lambda} = \beta_0 + \beta_1 M_i + \beta_2 S_i + \beta_3 M_i S_i
$$

where $M_i$ is nestling mass and $S_i$ a **dummy** variable

$$
S_i = \left\{\begin{array}{ll}
        1 & \mbox{if $i$ is warbler},\\
        0 & \mbox{otherwise}.
        \end{array}
        \right.
$$

The term $M_iS_i$ is an **interaction** term. Think of this as an additional explanatory variable in our model.
Effectively it lets us have **different** slopes for different species (without an interaction term we assume that
both species have the same slope for the relationship between begging rate and mass, and only the intercept differ).

The mean regression lines for the two species look like this:

* **Cuckoo** ($S_i=0$)

$$
\begin{aligned}
    \log{\lambda} & = \beta_0 + \beta_1 M_i + (\beta_2 \times 0)  + (\beta_3 \times M_i \times 0)\\
    \log{\lambda} & = \beta_0 + \beta_1 M_i
\end{aligned}
$$
    
* **Intercept** = $\beta_0$, **Gradient** = $\beta_1$

* **Warbler** ($S_i=1$)

$$
\begin{aligned}
    \log{\lambda} & = \beta_0 + \beta_1 M_i + (\beta_2 \times 1)  + (\beta_3 \times M_i \times 1)\\
    \log{\lambda} & = \beta_0 + \beta_1 M_i + \beta_2 + \beta_3M_i\\
 
\end{aligned}
$$

Fit the model with the interaction term in R:

```{r, echo = F, eval = T}
cuckoo_glm1 <- glm(Beg ~ Mass + Species + Mass:Species, data=cuckoo, family=poisson(link="log"))
```

```{r}
cuckoo_glm1 <- glm(Beg ~ Mass + Species + Mass:Species, data=cuckoo, family=poisson(link="log"))

summary(cuckoo_glm1)
```
> Note there appears to be a negative interaction effect for Species:Mass, indicating that Begging calls do not increase with mass as much as you would expect for Warblers as compared to Cuckoos.

Plot the mean regression line for each species:

```{r, eval = TRUE}
# using augment allows you to generate fitted outcomes from the regression, make sure to set the predictions onto the response scale in order to 'back transform` the data onto the original scale

broom::augment(cuckoo_glm1, type.predict = "response") %>% 
ggplot(aes(x=Mass, y=.fitted, colour=Species)) + 
  geom_point() +
  geom_line()+
  scale_colour_manual(values=c("green3","turquoise3"))+
  theme_minimal()

```

We get an exponential curve in the scale of the original data, which is the **same** as a straight line in the log-scaled version of the data. So if we fit the same model without specifying `type.predict = "response"`  Then we get the fitted generalized linear response.

```{r, eval = TRUE}
broom::augment(cuckoo_glm1) %>% 
ggplot(aes(x=Mass, y=.fitted, colour=Species)) + 
  geom_point() +
  geom_line()+
  scale_colour_manual(values=c("green3","turquoise3"))+
  theme_minimal()

```

Compare the new Poisson model fits to the ordinary least squares model. We can see that although the homogeneity of variance is far from perfect, the curvature in the model has been drastically reduced (this makes sense as now we have a model fitted to exponential data), and the qqplot is within acceptable confidence intervals. 

```{r, eval = T}
performance::check_model(cuckoo_glm1, 
                         check = c("homogeneity",
                                   "qq"))

```



```{r}
summary(cuckoo_glm1)
```
```
Call:
glm(formula = Beg ~ Mass + Species + Mass:Species, family = poisson(link = "log"), 
    data = cuckoo)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-7.5178  -2.8298  -0.6672   1.5564   6.0631  

Coefficients:
                     Estimate Std. Error z value Pr(>|z|)    
(Intercept)          0.334475   0.227143   1.473  0.14088    
Mass                 0.094847   0.007261  13.062  < 2e-16 ***
SpeciesWarbler       0.674820   0.259217   2.603  0.00923 ** 
Mass:SpeciesWarbler -0.021673   0.008389  -2.584  0.00978 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 970.08  on 50  degrees of freedom
Residual deviance: 436.05  on 47  degrees of freedom
AIC: 615.83

Number of Fisher Scoring iterations: 6
```

A reminder of how to interpret the regression coefficients of a model with an interaction term

- Intercept = $\beta 0$ (intercept for the **reference\baseline** so here the **log** of the mean number of begging calls for **cuckoos** when mass = 0)

- Mass = $\beta1$ (slope: the change in the **log** mean count of begging calls for every gram of bodyweight for **cuckoos**)

- SpeciesWarbler = $\beta2$ (the **log** mean increase/decrease in begging call rate of the **warblers** relative to cuckoos) 

- Mass:SpeciesWarbler =$\beta3$ (the **log** mean increase/decrease in the **slope** for **warblers** relative to cuckoos)

> Note - because this is a Poisson distribution where variance is fixed with the mean we are using z scores. Estimates are on a log scale because of the link function - this means so are any S.E. or confidence intervals

## Estimates and Intervals

Remember that not only is this **Poisson** model fitting variance using a Poisson and not Normal distribution. It is also relating the predictors to the response variable with a "*log-link*" this means we need to exponentiate our estimates to get them on the same scale as the response (y) variable. Until you do this all the model estimates are logn(y).

```{r}
exp(coef(cuckoo_glm1)[1]) ### Intercept - Incidence rate at Mass=0, and Species = Cuckoo

exp(coef(cuckoo_glm1)[2]) ### Change in the average incidence rate with Mass 

exp(coef(cuckoo_glm1)[3]) ### Change in the incidence rate intercept when Species = Warbler and Mass = 0
 
exp(coef(cuckoo_glm1)[4]) ### The extra change in incidence rate for each unit increase in Mass when Species = Warbler (the interaction effect)

```

Luckily when you tidy your models up with `broom` you can specify that you want to put model predictions on the response variable scale by specifying exponentiate=T which will remove the log transformation, and allow easy calculation of confidence intervals. 

```{r, eval=FALSE}
broom::tidy(cuckoo_glm1, 
            exponentiate=T, 
            conf.int=T)

```

```{r, echo=FALSE, eval =TRUE}
broom::tidy(cuckoo_glm1, 
            exponentiate=T, 
            conf.int=T) %>% 
    kableExtra::kbl() %>% 
  kableExtra::kable_minimal() 
```

### Interpretation

It is **very important** to remember whether you are describing the results on the log-link scale or the original scale. It would usually make more sense to provide answers on the original scale, but this means you must first exponentiate the relationshio between response predictors as described above when writing the results. 

In this example we wished to infer the relationship between begging rates and mass in these two species. 

I hypothesised that the rate of begging in chicks would increase as their body size increased. Interestingly I found there was a significant interaction effect with mass and species, where Warbler chicks increased their calling rate with mass at a rate that was only 0.98 [95%CI: 0.96-0.99] that of Cuckoo chicks (Poisson GLM: $\chi^2$~1,47~ = 6.77, *P* = 0.009). This meant that while at hatching Warbler chicks start with a mean call rate that is higher than their parasitic brood mates, this quickly reverses as they grow. 

```{r}
# For a fixed  mean-variance model we use a Chisquare distribution
drop1(cuckoo_glm1, test = "Chisq")

# emmeans can be another handy function - if you specify response then here it provideds the average call rate for each species, at the average value for any continuous measures - so here the average call rate for both species at an average body mass of 20.3

emmeans::emmeans(cuckoo_glm1, specs = ~ Species:Mass, type = "response")


```

## Overdispersion

There is one **extra** check we need to apply to a Poisson model and that's for **overdispersion**

Poisson (and binomial models) assume that the variance is *equal to the mean.*  

However, if there is **residual deviance that is bigger than the residual degrees of freedom** then there is *more* variance than we expect from the prediction of the mean by our model. 

Overdispersion can be diagnosed by $\frac{residual~deviance}{residual~degrees~of~freedom}$ which from our example here 'summary()' is $\frac{436}{47} = 9.3$

Overdispersion statistic values **> 1 = Overdispersed**

Overdispersion is a result of larger than expected variance for that mean under a Poisson distribution, this is clearly an issue with our model!

Luckily a simple fix is to fit a *quasi-likelihood* model which accounts for this, think of "quasi" as "sort of but not completely" Poisson. 

```{r}
cuckoo_glm2 <- glm(Beg ~ Mass+Species+Mass:Species, data=cuckoo, family=quasipoisson(link="log"))

```
```
Call:
glm(formula = Beg ~ Mass + Species + Mass:Species, family = quasipoisson(link = "log"), 
    data = cuckoo)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-7.5178  -2.8298  -0.6672   1.5564   6.0631  

Coefficients:
                    Estimate Std. Error t value Pr(>|t|)    
(Intercept)          0.33448    0.63129   0.530    0.599    
Mass                 0.09485    0.02018   4.700  2.3e-05 ***
SpeciesWarbler       0.67482    0.72043   0.937    0.354    
Mass:SpeciesWarbler -0.02167    0.02332  -0.930    0.357    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for quasipoisson family taken to be 7.7242)

    Null deviance: 970.08  on 50  degrees of freedom
Residual deviance: 436.05  on 47  degrees of freedom
AIC: NA

Number of Fisher Scoring iterations: 6
```

As you can see, while none of the estimates have changed, the standard errors (and therefore our confidence intervals) have, this accounts for the greater than expected uncertainty we saw with the deviance, and applies a more cautious estimate of uncertainty. The interaction effect appears to no longer be significant at $\alpha$ = 0.05, now that we have wider standard errors.

> Note - because we are now estimating the variance again, the test statistics have reverted to *t* distributions and anova and drop1 functions should specify the F-test again.

<details><summary>**Question - How would you write up an Analysis Methods section?**</summary>

I used a Poisson log-link Generalized Linear Model with quasi-likelihoods to account for overdispersion to analyse begging call rates in Warbler and Cuckoo chicks. The species of chick was included as a categorical predictor and mass was included as a continuous predictor. 

The initial model also included an interaction term between species and mass, but this was removed from the final model as removal of this term did not significantly alter the fit of the model (ANOVA). 

All analyses were carried out in R (ver 4.1.3) (R Core Team 2021) with the following packages;  tidyverse (Wickham et al 2019), performance (Lüdecke et al 2021) for checking model assumptions, and MASS (Venables & Ripley 2002) for model comparisons.

## Logistic regression (for binary data)

When our response variable is binary, we can use a glm with a **binomial** error distribution

So far we have only considered continuous and discrete data as response variables. What if our response is a categorical variable (e.g passing or failing an exam, voting yes or no in a referendum, whether an egg has successfully fledged or been predated, infected/uninfected, alive/dead)? 

We can model the **probability** $p$ of being in a particular class as a function of other
explanatory variables.

These type of **binary** data are assumed to follow a **Bernoulli** distribution (which is a special case of *Binomial*) which has the following characteristics:

$$
Y \sim \mathcal{Bern}(p)
$$

* **Binary** variable, taking the values 0 or 1 (yes/no, pass/fail).
* A **probability** parameter $p$, where $0 < p < 1$.
* **Mean** = $p$  
* **Variance** = $p(1 - p)$

```{r bernplot, echo=F, fig.width=9, fig.height=3}
par(mfrow = c(1, 3))
x <- 0:1
p <- c(0.1, 0.5, 0.8)
barplot(dbinom(x, size = 1, prob = p[1]), col = cols[1], ylab = "Probability", xlab = "X", main = paste0("p = ", p[1]), ylim = c(0, 1), names.arg = x)
for(i in 2:length(p)) barplot(dbinom(x, size = 1, prob = p[i]), col = cols[i], ylab = "Probability", xlab = "X", main = paste0("p = ", p[i]), ylim = c(0, 1), names.arg = x)
par(mfrow = c(1, 1))
```

Let us now place the Gaussian (simple linear regression), Poisson and logistic models next to each other:


$$
\begin{aligned}
Y & \sim \mathcal{N}(\mu, \sigma^2) &&& Y  \sim \mathcal{Pois}(\lambda) &&& Y  \sim \mathcal{Bern}(p)\\
\mu & = \beta_0 + \beta_1X &&& \log{\lambda} = \beta_0 + \beta_1X &&& ?? = \beta_0 + \beta_1X
\end{aligned}
$$

Now we need to fill in the `??` with the appropriate term. Similar to the Poisson regression case, 
we cannot simply model the probabiliy as $p = \beta_0 + \beta_1X$, because $p$ **cannot** be negative.
$\log{p} = \beta_0 + \beta_1X$ won't work either, because $p$ cannot be greater than 1. Instead we 
model the **log odds** $\log\left(\frac{p}{1 - p}\right)$ as a linear function. So our logistic regression model looks
like this:

$$
\begin{aligned}
Y  & \sim \mathcal{Bern}(p)\\
\log\left(\frac{p}{1 - p}\right) &  = \beta_0 + \beta_1 X
\end{aligned}
$$

Again, note that we are still "only" fitting straight lines through our data, but this time in the log odds space.
As a shorthand notation we write $\log\left(\frac{p}{1 - p}\right) = \text{logit}(p) = \beta_0 + \beta_1 X$.

```{r, echo=F, fig.width=5, fig.height = 5}
x <- seq(-10, 10, length = 100)
plot(x, x, lwd=2, col='black', xlab="X", ylab="logit(p)", type = "l")
```

We can also re-arrange the above equation so that we get an expression for $p$

$$
p = \frac{e^{\beta_0 + \beta_1 X}}{1 + e^{\beta_0 + \beta_1 X}}
$$

```{r, echo=F, fig.width=5, fig.height=5}
plot(x, exp(x) / (1 + exp(x)), lwd = 2, col = 'black', xlab = "X", ylab = "p", type = "l")
```

Note how $p$ can only vary between 0 and 1. 

To implement the logistic regression model in R, we choose `family=binomial(link=logit)` (the Bernoulli distribution is a special case of the Binomial distribution).

```
glm(response ~ explanatory, family=binomial(link=logit))
```

[The Challenger Disaster](https://en.wikipedia.org/wiki/Space_Shuttle_Challenger_disaster#O-ring_concerns)

In 1985, NASA made the decision to send the first civilian into space. 

This decision brought a huge amount of public attention to the STS-51-L mission, which would be Challenger’s 25th trip to space and school teacher Christa McAuliffe’s 1st. On the afternoon of January 28th, 1986 students around America tuned in to watch McAuliffe and six other astronauts launch from Cape Canaveral, Florida. 73 seconds into the flight, the shuttle experienced a critical failure and broke apart in mid air, resulting in the deaths of all seven crewmembers: Christa McAuliffe, Dick Scobee, Judy Resnik, Ellison Onizuka, Ronald McNair, Gregory Jarvis, and Michael Smith.

After an investigation into the incident, it was discovered that the failure was caused by an O-ring in the solid rocket booster. Additionally, it was revealed that such an incident was foreseeable.

In this half of the worksheet we will discuss how the right statistical model could have predicted the critical failure of an O-ring on that day. 


```{r, eval=FALSE}
Challenger <- read_csv("data/Challenger.csv")
```

```{r, echo=FALSE, eval=TRUE}
Challenger <- read_csv("data/Challenger.csv")
```

```{r}
head(Challenger)
```

The data columns are:

- **oring_tot**: Total number of orings on the flight

- **oring_dt** : number of orings that failed during a flight

- **temp**: Outside temperature on the date of the flight

- **flight** order of flights

It was frequently discussed issue that temperature might play a role in the critical safety of the o-rings on the shuttles.
One of the biggest mistakes made in assessing the flight risk for the Challenger was to only look at the flights **where a failure had occurred**

```{r, eval = T}
Challenger %>% 
  filter(oring_dt > 0) %>% 
ggplot(aes(y=oring_dt, x=temp))+geom_point()+
  ggtitle("Temperature on flight launches where an O-ring incident occurred")
```

From this it was concluded that temperature did not appear to affect o-ring risk of failure, as o-ring failures were detected at a range of different temperatures.

However when we compare this to the full data that was available a very different picture emerges. 


```{r, eval = T}
Challenger %>% 
ggplot(aes(y=oring_dt, 
           x=temp))+
  geom_point()+
  geom_smooth(method="lm")+
  ggtitle("All launch data")
```

When we include the flights without incident *and* those with incident, we can see that there is a very clear relationship between temperature and the risk of an o-ring failure. It has been argued that the clear presentation of this data should have allowed even the casual observer to determine the high risk of disaster.

However if we want to understand the actual relationship between temperature and risk then there are several issues with fitting a linear model here - once again the data is an integer, and bounded by zero (our model predicts negative failure rates within the observed data range). 

We COULD consider this as suitable for a Poisson model - but if we are really interested in determining the binary risk of **having a flight with o-ring failure vs. no failure**. Then we should implement a GLM with a Binomial distribution.

We can use dplyr to generate a binary column of no incident '0' and fail '1' for anything >0. 

```{r, eval = T}
Challenger <- Challenger %>% 
  mutate(oring_binary = ifelse(oring_dt =='0', 0, 1))
```

Fitting a binary GLM 

```{r, echo=FALSE}
binary_model <- glm(oring_binary~temp, family=binomial, data=Challenger)
binary_model %>% broom::tidy(conf.int=T)
```

```{r, eval=TRUE, echo = FALSE}
binary_model <- glm(oring_binary~temp, family=binomial, data=Challenger)
broom::tidy(binary_model, conf.int=T) %>% 
  kableExtra::kbl() %>% 
  kableExtra::kable_minimal()

```

So we are now fitting the following model

$$
 Y \sim Bern(p)
$$
$$
\log\left[ \frac { P( \operatorname{oring\_binary} = fail) }{ 1 - P( \operatorname{oring\_binary} = fail) } \right] = \beta_{0} + \beta_{1}(\operatorname{temp})
$$
Which in R will look like this:

```{r}
binary_model <- glm(oring_binary~temp, family=binomial, data=Challenger)
```

- Intercept = $\beta_{0}$ = 23.77

When the temperature is 0&deg;F the mean *log-odds* are 23.77 [95%CI: 7.24-	58.19] for a failure incident in the O-rings

- Temp = $\beta_{1}$ = -0.37 [95%CI: -0.87 - -0.12]

For every rise in the temperature by 1&deg;F, the *log-odds* of a critical incident fall by 0.37.

### Probability from a binomial model

If we use the `emmeans()` function it will convert *log-odds* to estimate the probability of o-ring failure at the mean value of x (temperature).
But how does it do this?

```{r}
emmeans::emmeans(binary_model, specs=~temp, type="response")
```

This is the equation to work out probability using the **exponent** of the linear regression equation:

$$
P(\operatorname{risk of failure at }  X=69)\left[ \frac{e^{23.77+(-0.37 \times 69.6)}}{1+e^{23.77+(-0.37 \times 69.6)}} \right]
$$

Which produces the following result and we can confirm the risk of an o-ring failure on an *average* day is 0.15

```{r}
estimate_at_69.6 <- exp(coef(binary_model)[1]+coef(binary_model)[2]*69.6)

estimate_at_69.6/(1+estimate_at_69.6)

```

### Changes in probability

A useful *rule-of-thumb* can be the **divide-by-four** rule.

This can be described as the **maximum** difference in probability for a unit change in $X$ is $\beta/4$.

In our example the **maximum difference** in probability from a one degree change in Temp is $-0.37/4 = -0.09$

So the **maximum difference** in probability of failure corresponding to a one degree change is 9%


If you want to augment your data with the model, you can use the `augment()` function, remembering to specify `type.predict = "response` to get probabilities of o-ring failure (not log odds). 

```{r}
broom::augment(binary_model, type.predict="response", se_fit = T) 
```

Annoyingly a limitation of the augment function is that it won't produce 95% CI for predictions on glms. But I have written a short function to do this
Don't worry if this is a lot to get your head around - the main thing is use this code to produce 95% CI. 

```{r}
augment_glm <- function(mod, predict = NULL){
  fam <- family(mod)
  ilink <- fam$linkinv
  
  broom::augment(mod, newdata = predict, se_fit=T)%>%
    mutate(.lower = ilink(.fitted - 1.96*.se.fit),
           .upper = ilink(.fitted + 1.96*.se.fit), 
           .fitted=ilink(.fitted))
}

augment_glm(binary_model)

```


<details><summary>**EXERCISE - Use the augment_glm function to make a ggplot of the changing probability of O-ring failure with temperature**</summary>


```{r}

augment_glm(binary_model) %>% 
  ggplot(aes(x=temp, y=oring_binary))+geom_line(aes(x=temp, y=.fitted))+
  geom_ribbon(aes(ymin=.lower, ymax=.upper), alpha=0.2)

```
</details>

## Predictions

On the day the Challenger launched the outside air temperature was 36&deg;F

We can use augment to add our model to new data - and make predictions about the risk of o-ring failure

<details><summary>**Question - make a new dataset with the temperature on the day of the Challenger launch - what was the probability of o-ring failure?**</summary>


First - we make a new dataset with the temperature on the day of the Challenger Launch **36&deg;F**

```{r, eval = TRUE}
new_data <- tibble(temp=36, oring_binary=1)
new_data

```

```{r}
augment_glm(binary_model, new_data)
```
```
# A tibble: 1 x 6
   temp oring_binary .fitted .se.fit .lower .upper
  <dbl>        <dbl>   <dbl>   <dbl>  <dbl>  <dbl>
1    36            1    1.00    5.54  0.431   1.00
```
We can see from our fitted model, an O-ring failure on the day of the Challenger launch could have been predicted with a probability of >0.999 [95%CI: 0.43-1]

</details>

### Assumptions

The standard model checks for a binary model do not hold (check them), they are usually a mess! There are alternative methods of looking at how well your binary model works, but well not cover these here. 

### Write-up

Analysis: I used a Binomial logit-link Generalized Linear Model to analyse the effect of temperature on the likelihood of O-ring failure.

All analyses were carried out in R (ver 4.1.3) (R Core Team 2021) with the following packages;  tidyverse (Wickham et al 2019).

Results: I found a significant negative relationship between temperature and probability of o-ring failure (logit-odds = -0.37 [95%CI: -0.88 - -0.12], *z* = -2.1, d.f = 21, *P* = 0.036). At an average temperature of 69.6&deg;F the probability of o-ring failure was estimated at 0.15[0.03-0.45], but this rose to a near certainty of failure 0.99[0.43-1] at 36&deg;F.

>Note you could use drop1( test = "Chisq") here, but as there is only one, continuous variable, we can also report directly from the summary table. 

## Summary

**GLMs** are powerful and flexible.

They can be used to fit a wide variety of data types.

Model checking becomes trickier.

Extensions include:

* **mixed models**;
* **survival models**;
* **generalised additive models** (GAMs).


## Final checklist



