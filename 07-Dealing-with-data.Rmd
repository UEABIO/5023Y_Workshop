
# Dealing with data: dplyr - Week Eight

```{r , echo=FALSE, eval=TRUE, include=TRUE}
klippy::klippy(c('r', 'bash'), position = c('top', 'right'), tooltip_message = 'copy to clipboard', tooltip_success = 'Copied!')
```

```{r include=FALSE}
knitr::opts_chunk$set(eval=FALSE)
```


## Let's get going

You need to accept the latest assignment from [Github Classrooms](https://classroom.github.com/a/ifsL9ZE1).

We will be using this project until the end of term, so make sure you make regular commits, and push your work at the end of each session. 

## Introduction to dplyr

In chapters 3 and 4 we demonstrated a brief data analysis on the `palmerpenguins` dataset. We ran through several pipelines, but without going into huge amounts of detail on each section. 

In this chapter we are going to get really well acquainted with **dplyr** @R-dplyr. 

We will look at several core functions:

* `select` (get some columns)

* `filter` (get some rows)

* `arrange` (order the rows)

* `mutate` (make new columns)

* `group_by` (add grouping information)

* `summarise` (calculate summary information)

You should make careful notes about these functions and what they do. Build scripts with carefully added notes that you can use for future work

As you work through this (and other chapters) - make notes, if you take a break, set up a commit, or reach the end of a session - push your work to Github.

Make sure you are using the [R Cheat Sheets for dplyr](https://www.rstudio.com/resources/cheatsheets/)

## select

Start by setting up the packages you will need for this session

```{r}
library(tidyverse)
library(lubridate)

penguins <- read_csv("data/penguins_simple.csv")
```
> ** Note - if you don't have these packages available, then you will need to run `install.packages("tidyverse")` - you should do this in the *console* and **not** your script. 

We use select to *select variables* from a dataframe or tibble. for example:

```
data_set %>% 
  select(variable_1, variable_2)
```
> ** Note this is *pseudocode* an example, not something you should run.

* The data is piped into the first argument position of the `select` function

* We then include the arguments where each one is the name of a variable in the dataset

For example if we actually run this:

```{r}
penguins %>% 
  select(flipper_length_mm)
```

To look at flipper length - we should note a couple of things.

* Variable name is **not** in quotes

* The original data is unchanged e.g. penguins. Unless we assign the results of `select` with the assignment arrow (<-), the results will just be printed in the console

* The order you ask for the variables in `select` determines the order of the columns in any new dataset

* `select` returns a tibble

* If we want to keep most variables, but *remove one*, use the minus operator

```{r}
penguins <- penguins %>% 
  select(-flipper_length_mm)

```

```{block, type="rmdwarning"}
In the above option we just *overwrote* the penguin dataset with a new version that *does not* contain flipper length. 
Be careful - the above code will thrown an error message if you try to run it again (there is no longer a flipper length variable to remove). 
If you want to *undo* this, the easiest way is to re-run your script to just before this line, so you

```

You can also use select to keep sets of consecutive variables together

```{r}
penguins %>% 
  select(species:flipper_length_mm)
```

There are also a number of helper functions like `starts_with`, `ends_with`, `contains`, `matches`. So if we want to keep all the variables that start with "b"

```{r}
penguins %>% 
  select(starts_with("b"))

```

## mutate

Adding or creating new variables is a common task, we might want to make a log-transformation, subtract one value from another or use `mutate` to add a new date variable

```{r}
penguins <- penguins %>% 
  mutate(date_proper=dmy(date))

```

Sometimes we want to change the values being used. For example we might want to change "male" and "female" to some abbreviation like "M" and "F". (Probably not, but it's an example!).

```{r}
  penguins %>% 
  mutate(sex=case_when(sex == "male" ~ "M",
                       sex == "female" ~ "F"))

```

Things to know about `mutate`:

* Unless we assign the results of `mutate` back to an object (<-) the changes won't be saved

* We can use newly created variables in further calculations *within* the same `mutate`

## filter

`filter` is used to subset observations in a dataframe. We might want to see the observations where `flipper_length_mm` is larger or smaller than a fixed value. Or we might want to only see the data from female penguins, or a particular species. 

```{r}
penguins %>% 
  filter(sex == "female",
         species == "Adelie",
         flipper_length_mm < 180)

```

In this example we've created a subset of `penguins` that only includes the five observations where flipper length is less than 180mm in female, Adelie penguins. 

We can also set an either/or filter, for example if we only want small & large flipper lengths.

```{r}
penguins %>% 
  filter(species == "Adelie", 
         flipper_length_mm <180 | 
           flipper_length_mm >200)

```

This creates a subset of Adelie penguins, that only includes 14 observations where flipper length is less than 180mm or greater than 200mm. 

The vertical bar | is understood by R as OR. 

The alternative is to look at values *between* two amounts

```{r}
penguins %>% 
  filter(species == "Adelie",
         between(flipper_length_mm, 180,200))

```


## arrange

We use arrange to reorder the rows of our data. Instances where we 'need' to do this are rare. But we may often want to reorder rows so that we can understand the data more easily

```{r}
penguins_ordered <- penguins %>% 
  arrange(sex,body_mass_g)

# arrange data first by sex - all females then all males, within each sex order body mass from low to high
  
penguins_ordered %>% 
  select(penguin_id, sex, body_mass_g)
# view just a few variables

```

By default arrange sorts from low to high (and alphabetically) - we can reverse this if we wrap the variable names in the function `desc`

```{r}
penguins_reverse_ordered <- penguins %>% 
  arrange(desc(sex,body_mass_g))


  
penguins_reverse_ordered %>% 
  select(penguin_id, sex, body_mass_g)


# we can also apply this to specific variables
penguins_reverse_ordered <- penguins %>% 
  arrange(sex,desc(body_mass_g))

```


## Group and summarise

Very often we want to make calculations aobut groups of observations, such as the mean or median. We are often interested in comparing responses among groups. For example, we previously found the number of distinct penguins in our entire dataset

```{r}
penguins %>% 
  summarise(n_distinct(penguin_id))

```

Now consider when the groups are subsets of observations, as when we find out the number of penguins in each species and sex

```{r}
penguins %>% 
  group_by(species, sex) %>% 
  summarise(n_distinct(penguin_id))

```

We are using summarise and group_by a lot! They are very powerful functions:

* `group_by` adds *grouping* information into a data object, so that subsequent calculations happen on a *group-specific* basis. 

* `summarise` is a data aggregation function thart calculates summaries of one or more variables, and it will do this separately for any groups defined by `group_by`

### Using summarise

```{r}
penguins %>% 
  summarise(mean_flipper_length = mean(flipper_length_mm, na.rm=TRUE),
   mean_bill_length = mean(bill_length_mm, na.rm=TRUE))

```
> **Note - we provide informative names for ourselves on the left side of the =. 

There are a number of different calculations we can use including:

* `min` and `max` to calculate minimum and maximum values of a vector

* `mean` and `median` 

* `sd` and `var` calculate standard deviation and variance of a numeric vector

We can use several functions in `summarise`. Which means we can string several calculations together in a single step

```{r}
penguins %>% 
  summarise(n=n(),
            num_penguins = n_distinct(penguin_id),
            mean_flipper_length = mean(flipper_length_mm, na.rm=TRUE),
            prop_female = sum(sex == "female", na.rm=TRUE) / n())
            

```
> **Note - we have placed each argument on a separate line. This is just stylistic, it makes the code easier to read. 


### Summarize all columns

We can use the function `across` to count up the number of NAs in every column (by specifying `everything`). 

```{r}

penguins %>% 
  summarise(across(.cols = everything(), 
                   .fns = ~sum(is.na(.)))) %>% 
  glimpse()

```

It has two arguments, `.cols` and `.fns`. The `.cols` argument lets you specify column types, while the `.fns` argument applies the required function to all of the selected columns. 


```{r}
# the mean of ALL numeric columns in the data, where(is.numeric) hunts for numeric columns

penguins %>% 
  summarise(across(.cols = where(is.numeric), 
                   .fns = ~mean(., na.rm=TRUE)))

```

The above example calculates the means of any & all numeric variables in the dataset. 

The below example is a slightly complicated way of running the n_distinct for summarise. The `.cols()` looks for any column that contains the word "penguin" and runs the `n_distinct()`command of these

```{r}
# number of distinct penguins, as only one column contains the word penguin

penguins %>% 
  summarise(across(.cols = contains("penguin"), 
                   .fns = ~n_distinct(.))) %>% 
  glimpse()

```

### group_by summary

The `group_by` function provides the ability to separate our summary functions according to any subgroups we wish to make. The real magic happens when we pair this with `summarise` and `mutate`.

In this example, by grouping on the individual penguin ids, then summarising by n - we can see how many times each penguin was monitored in the course of this study. 

```{r}
penguin_stats <- penguins %>% 
  group_by(penguin_id) %>% 
  summarise(num=n())
```
> **Note - the actions of group_by are powerful, but group_by on its own doesn't change the visible structure of the dataframe. 

### More than one grouping variable

What if we need to calculate by more than one variable at a time? 

```{r}
penguins_grouped <- penguins %>% 
  group_by(sex, species)

```

 We can then calculate the mean flipper length of penguins in each of the six combinations

```{r}
penguin_summary <- penguins_grouped %>% 
summarise(mean_flipper = mean(flipper_length_mm, na.rm=TRUE))
```

Now the first row of our summary table shows us the mean flipper length (in mm) for female Adelie penguins. There are eight rows in total, six unique combinations and two rows where the sex of the penguins was not recorded(`NA`)

#### using group_by with mutate

When `mutate` is used with a grouped object, the calculations occur by 'group'. Here's an example:

```{r}
centered_penguins <- penguins %>% 
  group_by(sex, species) %>% 
  mutate(flipper_centered = flipper_length_mm-mean(flipper_length_mm, na.rm=TRUE))

```

Here we are calculating a **group centered mean**, this new variable contains the *difference* between each observation and the mean of whichever group that observation is in. 

### remove group_by

On occasion we may need to remove the grouping information from a dataset. This is often required when we string pipes together, when we need to work using a grouping structure, then revert back to the whole dataset again

Look at our grouped dataframe, and we can see the information on groups is at the top of the data:

```
# A tibble: 344 x 10
# Groups:   sex, species [8]
   species island bill_length_mm bill_depth_mm flipper_length_~ body_mass_g
   <chr>   <chr>           <dbl>         <dbl>            <dbl>       <dbl>
 1 Adelie  Torge~           39.1          18.7              181        3750
 2 Adelie  Torge~           39.5          17.4              186        3800
 3 Adelie  Torge~           40.3          18                195        3250
 ```


```{r}
centered_penguins %>% 
  ungroup()

```

Look at this output - you can see the information on groups has now been removed from the data. 

# Dealing with data part 2 - Week Nine

## Expanding the data toolkit

In this chapter we go through some more miscellaneous topics around dealing with data.

## Pipes

As you have seen we often link our dplyr verbs together with `pipes`. Using one function after another e.g. `mutate` then `group_by` and perhaps `summarise`
The pipe %>% allows us to make "human-readable" an logical strings of instructions. 

The two below examples of pseudocode would be read identically by R - but which one is easier for you to understand?

```{r, eval=TRUE, echo=FALSE, out.width="80%", fig.alt= "Two very different ways of presenting the same code"}
knitr::include_graphics("images/pipe.png")
```

One way we can try and breakdown the complexity of multiple nested brackets is to make lots of "intermediate" R objects:

```{r}
penguins_grouped <- group_by(penguins, species, sex)

penguins_grouped_full <- drop_na(penguins_grouped, sex)

penguins_flipper_length <- summarise(penguins_grouped_full, mean=mean(flipper_length_mm, na.rm=TRUE))

penguins_flipper_length

```
> **Note - nothing wrong with this, but look at how many R objects are cluttering up your environment tab which you will probably never use again!

Or...

```{r}
penguins %>% 
  group_by(., species, sex) %>% 
  drop_na(., sex) %>% 
  summarise(., mean=mean(flipper_length_mm))

```
> **Note - check for yourself whether the outcome is identical

The pipe is becoming increasingly popular - because it makes code so much more readable. The newest versions of base R (4.1 and above) have even incorporate their own version of a pipe `|>` (https://michaelbarrowman.co.uk/post/the-new-base-pipe/). 

But how does the pipe actually work? Well whenever you include a pipe in your code, it signals to take everything on the left-hand side of the pipe and place it as an "argument" in the code which then comes on the right hand side. The . in the code above shows you the placeholder where the argument is placed. 

When you use the pipe (as you have been doing previously), you don't actually need to include the . for most functions. If you don't put it in, the pipe will simply place it into the *first argument* position. For this reason you will see that all dplyr functions have the first argument as the data. 

```{r}
penguins %>% 
  group_by(species, sex) %>% 
  drop_na(sex) %>% 
  summarise(mean=mean(flipper_length_mm))

```

## Strings

Datasets often contain words, and we call these words "strings". Often these aren't quite how we want them to be, but we can manipulate these as much as we like. Functions in the package `stringr` @R-stringr, are fantastic. And the number of different types of manipulations are endless

```{r}
str_replace_all(names(penguins), c("e"= "E"))
```

### separate

Sometimes a string might contain two pieces of information in one. This does not confirm to our tidy data principles. But we can easily separate the information with `separate` from `tidyr` @R-tidyr

First we produce some made-up data

```{r}
df <- tibble(label=c("a-1", "a-2", "a-3")) 
#make a one column tibble
df
```

```{r}
df %>% 
  separate(label, c("treatment", "replicate"), sep="-")

```

We started with one variable called `label` and then split it into two variables, `treatment` and `replicate`, with the split made where `-` occurs. 
The opposite of this function is `unite()`

### More stringr

Check out (https://stringr.tidyverse.org/index.html) @R-stringr


```{r}
penguins %>% 
  mutate(species=str_to_upper(species))

```

```{r}
penguins %>% 
  mutate(species=str_remove_all(species, "e"))

```

We can also trim leading or trailing empty spaces with `str_trim`. These are often problematic and difficult to spot e.g.

```{r}
df2 <- tibble(label=c("penguin", " penguin", "penguin ")) 
df2
```

We can easily imagine a scenario where data is manually input, and trailing or leading spaces are left in. These are difficult to spot by eye - but problematic because as far as R is concerned these are different values. We can use the function `distinct` to return the names of all the different levels it can find in this dataframe.

```{r}
df2 %>% 
  distinct()
```

If we pipe the data throught the `str_trim` function to remove any gaps, then pipe this on to `distinct` again - by removing the whitespace, R now recognised just one level to this data. 

```{r}
df2 %>% 
  mutate(label=str_trim(label, side="both")) %>% 
  distinct()

```
A quick example of how to extract partial strings according to a pattern is to use `grepl`. Combined with `filter` it is possible to subset dataframe by searching for all the strings that match provided information, such as all the penguin IDs that start with "N1"

```{r}
penguins %>% 
  filter(grepl("N1", individual_id)) %>% 
  distinct(individual_id)

```


## Dates and times

Dates and times are difficult. 

There's a lot of different ways to write the same date

13-10-2019

10-13-2019

13-10-19

13th Oct 2019

2019-10-13

This variability makes it difficult to tell our software how to read the information, luckily we can use `lubridate` @R-lubridate. We can tell R the order of our date (or time) data.

Back in the last chapter (\@ref(mutate)), we used `mutate` and `lubridate` to convert date data which had been parsed as a string, into date format with the function `dmy()`. Depending on how we interpret the date ordering in a file, we can use `ymd`, `ydm`, `mdy` etc. 

If you get a warning that some dates could not be parsed, then you might find the date date has been inconsistently entered into the dataset.

```{r}
penguins %>% 
  select(date_egg, date_egg_proper) %>% 
  head()

```

Once we have established our date data, we are able to perform calculations. Such as the date range across which our data was collected. Try this with our variable in string form and it will provide the alphabetical order instead.  

```{r}
penguins %>% 
  summarise(min_date=min(date_egg_proper),
            max_date=max(date_egg_proper))
```

### Calculations with dates

How many times was each penguin measured, and across what total time period?

```{r}
penguins %>% 
  group_by(individual_id) %>% 
  summarise(min=min(date_egg_proper), 
            max=max(date_egg_proper), 
            difference = max-min, 
            n=n())
```

Cool we can also convert intervals such as days into weeks, months or years with `dweeks(1)`, `dmonths(1)`, `dyears(1)`.

As with all cool functions, you should check out the RStudio cheat sheet for more information. Date type data is common in datasets, and learning to work with it is a uesful skill. 


```{r}
penguins %>% 
  group_by(individual_id) %>% 
  summarise(min=min(date_egg_proper), 
            max=max(date_egg_proper), 
            years = (max-min)/dyears(1),
            n=n()) %>% 
  arrange(desc(difference))

```

## Pivot

In the previous chapters we discussed the principles of tidy data (\@ref(tidy-data)), tidy data is easy to analyse, but not always the format you will find data in.

The most likely format you will find data in is a "wide format", where we have columns of related data. Luckily `tidyr` contains a number of **pivot** functions


```{r , echo=FALSE, eval=TRUE}
knitr::include_graphics("images/original-dfs-tidy.png")
```


Let's start with some dummy data - we will make a dataframe of three penguins and the number of three types of prey they are observed to eat over a week:

```{r}

penguin_id <- c("N1A1","N1A2","N2A1")
krill <- c(70,20,43)
fish <- c(5, 19,4)
squid <- c(11,5,0)


df3 <- tibble(penguin_id, krill, fish, squid)
df3
```

This dataset is perfectly legible, but does not confirm to tidy data principles, each row is not a unique observation, but instead contains three observations of types of prey eaten.
Most of the time, we can make data "tidy" but pivoting wide data into a long format. In this example we should rearrange the data to produce a longer dataframe with fewer columns. We should make a new column for prey "type" and a column for "amount"

```{r}
df3_long <- df3 %>% 
  pivot_longer(cols=(krill:squid), names_to = "prey_type", values_to = "consumption_per_week")
df3_long
```

It then becomes extremely easy to plot this data:

```{r}
df3_long %>% 
  ggplot(aes(x=penguin_id, y=consumption_per_week, fill=prey_type))+
  geom_bar(stat="identity", position=position_dodge())

```

Once again, there's an RStudio cheatsheet for this, so check it out!

You may very occasionally need to use `pivot_wider()` to generate tidy data, but it's unusual, the above scenario is the most likely messy data you will encounter!




## Summing up 

### What we learned

You have learned:

The most common data manipulation functions you will need to import and tidy data, and the way in which they operate. 

* How to create new columns as products of functions or calculations

* How to select and filter data to access the subsets you are interested in

* How to apply functions to data groups

* How the pipe works, and why we use it

* How to deal with data subtypes like strings and dates

* How to reshape data with pivot

You have used `tidyverse` and the functions made available from:

* `dplyr` @R-dplyr

* `tidyr` @R-tidyr

You have also used two packages, which are also installed as part of the tidyverse, but have to be called with separate library() functions

* `lubridate` @R-lubridate

* `stringr` @R-stringr


### Further Reading, Guides and tips

[R Cheat Sheets](https://www.rstudio.com/resources/cheatsheets/)


